@misc{dmonte2024generalizedoffensivelanguageidentification,
      title={Towards Generalized Offensive Language Identification}, 
      author={Alphaeus Dmonte and Tejas Arya and Tharindu Ranasinghe and Marcos Zampieri},
      abstract={The prevalence of offensive content on the internet, encompassing hate speech and cyberbullying, is a pervasive issue worldwide. Consequently, it has garnered significant attention from the machine learning (ML) and natural language processing (NLP) communities. As a result, numerous systems have been developed to automatically identify potentially harmful content and mitigate its impact. These systems can follow two approaches; (1) Use publicly available models and application endpoints, including prompting large language models (LLMs) (2) Annotate datasets and train ML models on them. However, both approaches lack an understanding of how generalizable they are. Furthermore, the applicability of these systems is often questioned in off-domain and practical environments. This paper empirically evaluates the generalizability of offensive language detection models and datasets across a novel generalized benchmark. We answer three research questions on generalizability. Our findings will be useful in creating robust real-world offensive language detection systems.},
      year={2024},
      eprint={2407.18738},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.18738}, 
}

@InProceedings{10.1007/978-3-031-70242-6_24,
  author="Mander, Stephen
  and Phillips, Jesse",
  editor="Rapp, Amon
  and Di Caro, Luigi
  and Meziane, Farid
  and Sugumaran, Vijayan",
  title="LiSAScore: Exploring Linear Sum Assignment onÂ BertScore",
  booktitle="Natural Language Processing and Information Systems",
  year="2024",
  publisher="Springer Nature Switzerland",
  address="Cham",
  pages="249--257",
  abstract="Metrics play a crucial role in evaluating the performance of machine learning models. In the context of Natural Language Processing (NLP) tasks, such as text summarization and machine translation, Natural Language Generation (NLG) metrics such as Bleu and Rouge have been widely used. However, these metrics are based on n-gram matching and do not capture the semantic similarity between the generated and reference texts. To address this, BertScore has emerged as a popular evaluation metric that uses a pre-trained Large Language Model (LLM) to measure semantic similarity between two sentences. Unlike n-gram-based metrics, BertScore uses the contextual and semantic embeddings of words, allowing flexible semantic evaluation. We outline a number of hypotheticals in which the dependence of BertScore on token embedding cosine similarity may be exploited. The comparative distribution of BertScores on a set of reference - prediction pairs mean that results often scale differently with training to traditional metrics, which requires more expertise when interpreting results.",
  isbn="978-3-031-70242-6",
  url="https://link.springer.com/chapter/10.1007/978-3-031-70242-6_24"
}

